{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T19:49:51.043090Z",
     "start_time": "2025-07-23T19:49:48.921092Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "\n",
    "class TinyCNN(nn.Module):\n",
    "    def __init__(self, num_classes=50):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((12, 32)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 12 * 32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:49:51.632091Z",
     "start_time": "2025-07-23T19:49:51.047092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_mel(mel, label):\n",
    "    plt.imshow(mel.squeeze(), origin='lower', aspect='auto', cmap='magma')\n",
    "    plt.title(f\"Genres: {torch.nonzero(label).squeeze().tolist()}\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ],
   "id": "4aae919cb3cede41",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:49:57.698003Z",
     "start_time": "2025-07-23T19:49:51.856092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from data.procesing import ParseData\n",
    "\n",
    "ParseData(\"raw_30s_cleantags_125artists\", \"E:/SongsDataset/raw_30s_melspecs/\", \"E:/SongsDataset/tiny-melspec-dataset\", features=96, chunks_per_batch=4096, chunk_size=256, per_label=25, labels_to_include=10, chunks_per_song=3)"
   ],
   "id": "58c58262dc698d72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 55215 tracks, 11217 albums, 3552 artists\n",
      "There are 50 genres in this partition.\n",
      "There are 15 moods/themes in this partition.\n",
      "There are 20 instruments in this partition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55215/55215 [00:03<00:00, 17575.94it/s]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:49:58.893487Z",
     "start_time": "2025-07-23T19:49:58.798489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "class SmallDataset(Dataset):\n",
    "    def __init__(self, songs, labels):\n",
    "        self.songs = songs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.songs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.songs[idx], self.labels[idx]\n",
    "\n",
    "songs = torch.load(\"E:/SongsDataset/tiny-melspec-dataset/data/0686.pt\")\n",
    "labels = torch.load(\"E:/SongsDataset/tiny-melspec-dataset/genre_labels/0686.pt\")\n",
    "\n",
    "tiny_dataset = SmallDataset(songs, labels)"
   ],
   "id": "12cf33d72c52b157",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:49:58.989487Z",
     "start_time": "2025-07-23T19:49:58.974489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tiny_dataset,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")"
   ],
   "id": "5e731f7e3c9cd17f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:49:59.162487Z",
     "start_time": "2025-07-23T19:49:59.147488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "\n",
    "def train(model, train_dataloader, config):\n",
    "    # Training setup\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)  # L2 regularization\n",
    "    model.to(\"cuda\", config.dtype)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(40):\n",
    "        train_loss_total = 0\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.squeeze(0).unsqueeze(1).to(\"cuda\", config.dtype)\n",
    "            labels = labels.squeeze(0).to(\"cuda\", config.dtype)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_total += loss.item()\n",
    "\n",
    "        train_loss_average = train_loss_total / len(train_dataloader)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss_average:.4f}\")\n",
    "\n",
    "        torch.save(model, f\".\\\\{config.save_path}\\\\Classifier-Epoch-{epoch + 1}.pt\")\n",
    "\n",
    "def evaluate(model, dataloader, criterion, config):\n",
    "    test_loss_total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.squeeze(0).unsqueeze(1).to(\"cuda\", config.dtype)\n",
    "            labels = labels.squeeze(0).to(\"cuda\", config.dtype)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss_total += loss.item()\n",
    "\n",
    "            all_preds.extend(outputs.sigmoid().cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return test_loss_total / len(dataloader), all_preds, all_labels\n",
    "\n",
    "def model_size(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ],
   "id": "ee4c873d7f5815c9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:50:01.330023Z",
     "start_time": "2025-07-23T19:50:01.293509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "class Config:\n",
    "    # === General ===\n",
    "    model_name = \"Tiny-CNN-Overfitter\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float32\n",
    "    save_path = f\"trained_models\\\\{model_name}\\\\\"\n",
    "    seed = 42\n",
    "\n",
    "    # === Training ===\n",
    "    num_epochs = 30\n",
    "    batch_size = 24\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "    warmup_percent = 0.15\n",
    "    max_grad_norm = 1.0\n",
    "    log_every = 10  # steps between logs (optional)\n",
    "    save_checkpoints = True\n",
    "\n",
    "    # === Dataset ===\n",
    "    use_masks = True\n",
    "    num_workers = 4\n",
    "    val_split = 0.2\n",
    "    shuffle = True"
   ],
   "id": "f2556d8f3bf13910",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T19:50:06.030062Z",
     "start_time": "2025-07-23T19:50:02.867021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = TinyCNN(num_classes=50)\n",
    "print(f\"{model_size(model)} Parameters\")\n",
    "train(model, train_dataloader, Config)"
   ],
   "id": "572dd13ec04837fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6317938 Parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:01<00:00, 185.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.0588\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory .\\trained_models\\Tiny-CNN-Overfitter\\ does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m TinyCNN(num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_size(model)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m Parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 3\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mConfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[6], line 34\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_dataloader, config)\u001B[0m\n\u001B[0;32m     30\u001B[0m train_loss_average \u001B[38;5;241m=\u001B[39m train_loss_total \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(train_dataloader)\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss_average\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 34\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_path\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mClassifier-Epoch-\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepoch\u001B[49m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;250;43m \u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.pt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\.venv\\lib\\site-packages\\torch\\serialization.py:943\u001B[0m, in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001B[0m\n\u001B[0;32m    940\u001B[0m _check_save_filelike(f)\n\u001B[0;32m    942\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m--> 943\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_zipfile_writer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[0;32m    944\u001B[0m         _save(\n\u001B[0;32m    945\u001B[0m             obj,\n\u001B[0;32m    946\u001B[0m             opened_zipfile,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    949\u001B[0m             _disable_byteorder_record,\n\u001B[0;32m    950\u001B[0m         )\n\u001B[0;32m    951\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\.venv\\lib\\site-packages\\torch\\serialization.py:810\u001B[0m, in \u001B[0;36m_open_zipfile_writer\u001B[1;34m(name_or_buffer)\u001B[0m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    809\u001B[0m     container \u001B[38;5;241m=\u001B[39m _open_zipfile_writer_buffer\n\u001B[1;32m--> 810\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcontainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\.venv\\lib\\site-packages\\torch\\serialization.py:781\u001B[0m, in \u001B[0;36m_open_zipfile_writer_file.__init__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    777\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    778\u001B[0m         torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mPyTorchFileWriter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_stream, _compute_crc32)\n\u001B[0;32m    779\u001B[0m     )\n\u001B[0;32m    780\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 781\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPyTorchFileWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_compute_crc32\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Parent directory .\\trained_models\\Tiny-CNN-Overfitter\\ does not exist."
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "test_loss_average, all_probs, all_labels = evaluate(model, train_dataloader, criterion, Config)\n",
    "\n",
    "all_p_tensor = torch.stack([torch.tensor(x) for x in all_probs], dim=0).float()\n",
    "all_l_tensor = torch.stack([torch.tensor(x) for x in all_labels], dim=0).int()\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def graph(probs, labels):\n",
    "    # Store per-threshold values\n",
    "    thresholds = np.linspace(0, 1, 200)\n",
    "    precision_all = []\n",
    "    recall_all = []\n",
    "\n",
    "    for class_idx in range(probs.shape[1]):\n",
    "        y_true = labels[:, class_idx]\n",
    "        y_score = probs[:, class_idx]\n",
    "\n",
    "        precision, recall, thresh = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "        # Interpolate to get precision/recall at uniform thresholds\n",
    "        interp_precision = np.interp(thresholds, thresh, precision[:-1])  # precision[:-1] because it's len(thresh)+1\n",
    "        interp_recall = np.interp(thresholds, thresh, recall[:-1])\n",
    "\n",
    "        precision_all.append(interp_precision)\n",
    "        recall_all.append(interp_recall)\n",
    "\n",
    "    # Average across all classes\n",
    "    precision_mean = np.mean(precision_all, axis=0)\n",
    "    recall_mean = np.mean(recall_all, axis=0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(thresholds, precision_mean, label='Precision')\n",
    "    plt.plot(thresholds, recall_mean, label='Recall')\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Precision and Recall vs Threshold (Macro-Averaged over Genres)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "graph(all_p_tensor, all_l_tensor)"
   ],
   "id": "fb64a0e3d3e1f1f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
