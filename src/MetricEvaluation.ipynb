{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T21:43:06.441130Z",
     "start_time": "2025-10-20T21:42:27.386950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "from training.inference import get_latents\n",
    "from datasets import tqdm\n",
    "\n",
    "def generate_evaluation_dataset(model, dataloader, name, chunking=True, chunk_size=256):\n",
    "    model.mask_ratio = 0.0\n",
    "    model.to(\"cuda\")\n",
    "    latents, labels = get_latents(dataloader, model, chunking=chunking, chunk_size=chunk_size)\n",
    "    print(\"Saving...\")\n",
    "    for index, latent, label in tqdm(enumerate(zip(latents, labels))):\n",
    "        directory = f\"D:\\\\SongsDataset\\\\GTZAN\\\\latent_datasets\\\\{name}\\\\\"\n",
    "        label_name = directory + f\"{index}_label.pt\"\n",
    "        latent_name = directory + f\"{index}_data.pt\"\n",
    "        torch.save(latents, latent_name)\n",
    "        torch.save(label, label_name)"
   ],
   "id": "26862cea14b0f113",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:37<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m latents, labels \u001B[38;5;241m=\u001B[39m \u001B[43mget_latents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunking\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\Analyzer\\src\\training\\inference.py:49\u001B[0m, in \u001B[0;36mget_latents\u001B[1;34m(directory, model, chunking)\u001B[0m\n\u001B[0;32m     46\u001B[0m     data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(data)\n\u001B[0;32m     47\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 49\u001B[0m latent \u001B[38;5;241m=\u001B[39m \u001B[43mrun_batch\u001B[49m(model, data, averaging\u001B[38;5;241m=\u001B[39mchunking)\n\u001B[0;32m     50\u001B[0m all_latents\u001B[38;5;241m.\u001B[39mappend(latent)\n\u001B[0;32m     51\u001B[0m all_labels\u001B[38;5;241m.\u001B[39mappend(label)\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\\\pydevd_cython_win32_312_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_312_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\PyCharmProf\\PyCharm 2024.3.2\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1220\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1217\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1219\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1220\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharmProf\\PyCharm 2024.3.2\\plugins\\python-ce\\helpers\\pydev\\pydevd.py:1235\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1232\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1235\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1237\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from data.data_utils import GTZAN\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "directory = \"D:\\\\SongsDataset\\\\GTZAN\\\\\"\n",
    "GTZAN_dataset = GTZAN(directory)\n",
    "GTZAN_dataloader = DataLoader(\n",
    "    GTZAN_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    prefetch_factor=1\n",
    ")"
   ],
   "id": "5fe6cc6865b7454c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = torch.load(\"E:\\\\Coding\\\\SongAnalyzer\\\\Analyzer\\\\src\\\\trained_models\\\\Myna-CLS-ALIBI\\\\Epoch-103.pt\", weights_only=False)\n",
    "generate_evaluation_dataset(model, GTZAN_dataloader, \"ALIBI-Chunking-256\", chunking=True, chunk_size=256)\n",
    "generate_evaluation_dataset(model, GTZAN_dataloader, \"ALIBI-Chunking-8192\", chunking=True, chunk_size=8192)\n",
    "generate_evaluation_dataset(model, GTZAN_dataloader, \"ALIBI-Chunking-No-Chunking\", chunking=False, chunk_size=131072)"
   ],
   "id": "b03abf156baf1432"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = torch.load(\"E:\\\\Coding\\\\SongAnalyzer\\\\Analyzer\\\\src\\\\trained_models\\\\Myna-CLS-Sinusoidal\\\\Epoch-79.pt\", weights_only=False)\n",
    "generate_evaluation_dataset(model, GTZAN_dataloader, \"Sinusoidal-Chunking-256\", chunking=True, chunk_size=256)"
   ],
   "id": "78096b22d19bab28"
  },
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "def linear_probing(dataloader):\n",
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
