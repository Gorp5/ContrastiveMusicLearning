{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare Data",
   "id": "5b59abb1521cc780"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.data import ParseTaggedDataset\n",
    "\n",
    "full_dataset, full_masks, full_keys = ParseTaggedDataset(\"\")"
   ],
   "id": "d0613b3d78166446",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cdf8d29c5926d26a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T15:43:13.122350Z",
     "start_time": "2025-07-08T15:39:07.242611Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "from utils.data import MakeTripletDataset\n",
    "\n",
    "train_dataloader, test_dataloader = MakeTripletDataset(sample_length=256, batch_size=24)"
   ],
   "id": "e532f9f0890a4cae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T19:17:12.915603Z",
     "start_time": "2025-07-08T19:17:10.736602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.data import createDictionary\n",
    "\n",
    "metadata = createDictionary()"
   ],
   "id": "ca6caac681466e14",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T19:18:38.854239Z",
     "start_time": "2025-07-08T19:18:38.841692Z"
    }
   },
   "cell_type": "code",
   "source": "metadata[('track_0000951')]",
   "id": "330f403a880ef593",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TRACK_ID': 'track_0000951',\n",
       " 'ARTIST_ID': 'artist_000087',\n",
       " 'ALBUM_ID': 'album_000149',\n",
       " 'PATH': '51/951.mp3',\n",
       " 'DURATION': '199.7',\n",
       " 'TAGS': 'mood/theme---background'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T15:43:13.281350Z",
     "start_time": "2025-07-08T15:43:13.200353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "class Config:\n",
    "    # === General ===\n",
    "    model_name = \"my_model\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float32\n",
    "    save_path = \"./logs\"\n",
    "    seed = 42\n",
    "\n",
    "    # === Training ===\n",
    "    num_epochs = 30\n",
    "    batch_size = 24\n",
    "    learning_rate = 5e-5\n",
    "    weight_decay = 1e-5\n",
    "    warmup_percent = 0.15\n",
    "    max_grad_norm = 1.0\n",
    "    log_every = 10  # steps between logs (optional)\n",
    "    save_checkpoints = True\n",
    "\n",
    "    # === Dataset ===\n",
    "    dataset_path = \"./data\"\n",
    "    use_masks = True\n",
    "    num_workers = 4\n",
    "    val_split = 0.2\n",
    "    shuffle = True\n",
    "\n",
    "    # === Model Behavior ===\n",
    "    variational = False\n",
    "    autoregressive = False\n",
    "\n",
    "    # === Loss Coefficients ===\n",
    "    beta_schedule = \"log\"   # e.g., \"log\", \"linear\", etc. (for getBetaLog)\n",
    "    beta_max = 1.0\n",
    "    cycle_length = 2\n",
    "    contrastive_coeff = 0.1  # if using contrastive loss\n",
    "    margin = 0.1"
   ],
   "id": "b1b19949468fa7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Initialize Model",
   "id": "614913695eca1a35"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T15:43:19.066588Z",
     "start_time": "2025-07-08T15:43:15.630352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.AudioTransformer import AudioTransformer\n",
    "from utils.misc import model_size\n",
    "\n",
    "# ==== Model & Optimizer ====\n",
    "num_heads = 16\n",
    "num_layers = 16\n",
    "encoder_layers = 16\n",
    "decoder_layers = 5\n",
    "d_model = 256\n",
    "latent_space = 512\n",
    "dim_feedforward = 1024\n",
    "sample_length = 256\n",
    "projection_dim = 128\n",
    "dropout = 0.1\n",
    "\n",
    "name_extension = \"\"\n",
    "\n",
    "model = AudioTransformer(d_model=d_model, num_heads=num_heads, encoder_layers=encoder_layers, decoder_layers=decoder_layers, dim_feedforward=dim_feedforward, latent_space=latent_space, length=sample_length, dropout=dropout, name_extension=name_extension)\n",
    "print(f\"Parameters: {model_size(model)}\")"
   ],
   "id": "fbf7e5ec317606d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 85195840\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T18:12:22.725048Z",
     "start_time": "2025-07-08T15:43:19.148589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "from training.training import trainTriplet\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-6)\n",
    "trainTriplet(model, train_dataloader, test_dataloader, optimizer, Config, device=Config.device)"
   ],
   "id": "630afb5bb78d691a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: 100%|██████████| 6330/6330 [20:36<00:00,  5.12it/s]\n",
      "Evaluating: 100%|██████████| 704/704 [00:46<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train: 1.3852 | Triplet: 0.0000 Cos: 0.4368, MSE: 0.7315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: 100%|██████████| 6330/6330 [20:08<00:00,  5.24it/s]\n",
      "Evaluating: 100%|██████████| 704/704 [00:41<00:00, 17.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train: 1.1299 | Triplet: 0.0000 Cos: 0.3744, MSE: 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: 100%|██████████| 6330/6330 [20:01<00:00,  5.27it/s]\n",
      "Evaluating: 100%|██████████| 704/704 [00:41<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train: 1.0532 | Triplet: 0.0000 Cos: 0.3446, MSE: 0.6705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: 100%|██████████| 6330/6330 [20:17<00:00,  5.20it/s]\n",
      "Evaluating: 100%|██████████| 704/704 [00:42<00:00, 16.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train: 1.0140 | Triplet: 0.0000 Cos: 0.3267, MSE: 0.6591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: 100%|██████████| 6330/6330 [20:21<00:00,  5.18it/s]\n",
      "Evaluating: 100%|██████████| 704/704 [00:41<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train: 0.9895 | Triplet: 0.0000 Cos: 0.3169, MSE: 0.6524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: 100%|██████████| 6330/6330 [20:30<00:00,  5.14it/s]\n",
      "Evaluating: 100%|██████████| 704/704 [00:41<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train: 0.9724 | Triplet: 0.0000 Cos: 0.3102, MSE: 0.6453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|██████████| 6330/6330 [20:21<00:00,  5.18it/s]\n",
      "Evaluating: 100%|██████████| 704/704 [00:41<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train: 0.9612 | Triplet: 0.0000 Cos: 0.3103, MSE: 0.6444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30:   6%|▌         | 389/6330 [01:15<19:12,  5.16it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtraining\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m trainTriplet\n\u001B[0;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdamW(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-5\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-6\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m \u001B[43mtrainTriplet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mConfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mConfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\Analyzer\\src\\training\\training.py:145\u001B[0m, in \u001B[0;36mtrainTriplet\u001B[1;34m(model, train_loader, validation_loader, optimizer, config, device)\u001B[0m\n\u001B[0;32m    142\u001B[0m triplet_loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(anchor_positive_loss \u001B[38;5;241m-\u001B[39m anchor_negative_loss \u001B[38;5;241m+\u001B[39m config\u001B[38;5;241m.\u001B[39mmargin)\n\u001B[0;32m    143\u001B[0m loss \u001B[38;5;241m=\u001B[39m reconstruction_loss \u001B[38;5;241m+\u001B[39m triplet_loss\n\u001B[1;32m--> 145\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m clip_grad_norm_(model\u001B[38;5;241m.\u001B[39mparameters(), config\u001B[38;5;241m.\u001B[39mmax_grad_norm)\n\u001B[0;32m    147\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\.venv\\lib\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    824\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    825\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "844549eb145f64b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
