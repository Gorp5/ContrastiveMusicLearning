{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60706242edea8ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.processing import ParseBalanced\n",
    "\n",
    "directory = \"melspec-dataset-top-50-LIBROSA-256-Triplet\"\n",
    "data_directory = \"E:/mtg-jamendo/\"\n",
    "subset_file_name = \"autotagging_top50tags\"\n",
    "ParseBalanced(subset_file_name, f\"{data_directory}\", f\"D:/SongsDataset/{directory}\", convert=True, target_per_genre=1300, chunk_size=256, chunks_per_batch=1, write_individually=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T04:34:19.595059Z",
     "start_time": "2025-10-18T04:34:08.544888Z"
    }
   },
   "outputs": [],
   "source": [
    "from info_nce import InfoNCE\n",
    "from data.data_utils import *\n",
    "\n",
    "from libauc.losses.contrastive import GCLoss_v1\n",
    "\n",
    "directory = \"melspec-dataset-top-50-LIBROSA-256-Triplet\"\n",
    "data_directory = \"E:/mtg-jamendo/\"\n",
    "subset_file_name = \"autotagging_top50tags\"\n",
    "\n",
    "# augmentations = Compose([\n",
    "#     AddGaussianNoise(std=0.25),\n",
    "# ])\n",
    "\n",
    "class Config:\n",
    "    # === General ===\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float32\n",
    "    model_name = \"Myna-CLS-ALIBI-Convex\"\n",
    "    save_path = f\"trained_models\\\\{model_name}\\\\\"\n",
    "    seed = 42\n",
    "\n",
    "    # === Training ===\n",
    "    num_epochs = 256\n",
    "    batch_size = 128\n",
    "    learning_rate = 2e-4\n",
    "    weight_decay = 1e-5\n",
    "\n",
    "    coef = 1\n",
    "    cycles = 42\n",
    "    warmup = 0\n",
    "    gamma = 2.0\n",
    "\n",
    "    sogclr_tau = 0.1\n",
    "    sogclr_gamma = 0.9\n",
    "    gamma_schedule = 'constant' #'cosine'\n",
    "    epochs = 0\n",
    "    sogclr_eps = 1e-8\n",
    "    isogclr = False\n",
    "    rank = 0\n",
    "    lr_schedule = 'constant'\n",
    "\n",
    "    # === Dataset ===\n",
    "    transforms = None\n",
    "    use_masks = True\n",
    "    num_workers = 1\n",
    "    prefetch_factor = 1\n",
    "    val_split = 0.1\n",
    "    #pos_weight = (torch.ones(num_classes) * 50).to(\"cuda\")\n",
    "    criterion = InfoNCE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25b92472f73db5a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T04:34:19.614473Z",
     "start_time": "2025-10-18T04:34:19.600055Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "large_directory = directory\n",
    "\n",
    "train_dataset = StreamViewDataset(f\"D:\\\\SongsDataset\\\\{large_directory}\\\\train_set\\\\data\", \n",
    "                                  f\"D:\\\\SongsDataset\\\\{large_directory}\\\\train_set\\\\genre_labels\", pair_album=False, views=4)\n",
    "\n",
    "test_dataset  = StreamViewDataset(f\"D:\\\\SongsDataset\\\\{large_directory}\\\\test_set\\\\data\", \n",
    "                                  f\"D:\\\\SongsDataset\\\\{large_directory}\\\\test_set\\\\genre_labels\", pair_album=False, views=4)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.num_workers,\n",
    "    prefetch_factor=Config.prefetch_factor,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.num_workers,\n",
    "    prefetch_factor=Config.prefetch_factor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0b5351b3b35fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T18:58:37.535970Z",
     "start_time": "2025-10-13T18:58:35.386448Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from models.AudioPreCNNTransformer import AudioPreCNNTransformer\n",
    "from utils import misc\n",
    "\n",
    "model = AudioPreCNNTransformer(latent_space=512, input_dim=128, length=1024, num_heads=8, transformer_layers=8, d_model=256, dropout=0.1)\n",
    "print(f\"{misc.model_size(model)} Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699c79369ea9dfd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from models.AudioTransformer import AudioTransformer\n",
    "from utils import misc\n",
    "\n",
    "model = AudioTransformer(latent_space=32, input_dim=128, d_model=256, dim_feedforward=512, length=256, num_heads=8, encoder_layers=16, decoder_layers=16, dropout=0.1, use_alibi=True, custom_slopes=True)\n",
    "\n",
    "print(f\"{misc.model_size(model)} Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dabd0320a8ecaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from models.AudioTransformerWeaved import AudioTransformerWeaved\n",
    "from utils import misc\n",
    "\n",
    "model = AudioTransformerWeaved(latent_space=128, input_dim=128, d_model=256, dim_feedforward=512, length=1024, num_heads=8, encoder_layers=8, decoder_layers=8, dropout=0.1, use_alibi=True)\n",
    "print(f\"{misc.model_size(model)} Parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f15ad34c069a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T14:31:37.758363300Z",
     "start_time": "2025-10-14T14:31:13.623019Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from training.contrastive_training import train_contrastive\n",
    "from models.AudioViTEncoder import AudioViTEncoder\n",
    "from utils import misc\n",
    "\n",
    "Config.model_name = \"ViT-Contrastive-Embeddings-Masking-0.9\"\n",
    "Config.save_path = f\"trained_models\\\\{Config.model_name}\\\\\"\n",
    "\n",
    "model = AudioViTEncoder(patch_size=8, input_dim=128, num_heads=8, encoder_layers=8, length=256, d_model=256, dim_feedforward=512, dropout=0.1, latent_space=128, use_alibi=True, use_pooling=False, CLS=True, use_rope=False, masking_percent=0.0, variational=False)\n",
    "\n",
    "print(f\"{misc.model_size(model)} Parameters\")\n",
    "train_contrastive(model, test_dataloader, train_dataloader, Config, variational=False, train_masked=True, test_masked=False, album=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167d4f0a8538e6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T04:51:06.654519Z",
     "start_time": "2025-10-18T04:34:20.178030Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42719872 Parameters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8bc678a8934200879416b25ccfdb03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f248add866842a684809def6b190ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0] Train: Same Song Contrastive Loss = 4.7767\t|\tConvex Loss = 0.0081\n",
      "Test: Same Song Contrastive Loss = 4.5575\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21d37fda1a347639e45a14295316991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da9b8884e804245b71f4cc4f90fc017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train: Same Song Contrastive Loss = 4.7633\t|\tConvex Loss = 0.0104\n",
      "Test: Same Song Contrastive Loss = 4.4086\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7534ccbadc5346bca1678a18396483d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deea72e3eebb42e79a6ae23231b63493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] Train: Same Song Contrastive Loss = 4.5159\t|\tConvex Loss = 0.0091\n",
      "Test: Same Song Contrastive Loss = 4.2246\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d48ea20bdc24884b7316f7b5c9eb8ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646043ccff2542c8bbb36aa2cd4c6ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] Train: Same Song Contrastive Loss = 4.3460\t|\tConvex Loss = 0.0121\n",
      "Test: Same Song Contrastive Loss = 4.0049\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bcdad4e6a6b42f09596005d5efbacae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2481589364a48b7abc4bd95a80fb3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] Train: Same Song Contrastive Loss = 4.2404\t|\tConvex Loss = 0.0130\n",
      "Test: Same Song Contrastive Loss = 3.9485\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f17feaa01304d15b4fc6357cce6a155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7365ea341d478d9e3d92eb84f9b1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] Train: Same Song Contrastive Loss = 4.1484\t|\tConvex Loss = 0.0142\n",
      "Test: Same Song Contrastive Loss = 3.8786\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aceb2c600b4d4d826176e3b346e915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5df1ba93a684c11be477085cfd2c7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6] Train: Same Song Contrastive Loss = 4.0562\t|\tConvex Loss = 0.0161\n",
      "Test: Same Song Contrastive Loss = 3.8346\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ce8910a12a455c8c82e41fe8b3536f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4c0887947e4f70ad08d2943c21bfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 7] Train: Same Song Contrastive Loss = 3.9950\t|\tConvex Loss = 0.0164\n",
      "Test: Same Song Contrastive Loss = 3.7889\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b7f39fdf3f438598fdbf67e3be05ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd81f7e0c49040eda9cace33068bee65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 8] Train: Same Song Contrastive Loss = 3.9331\t|\tConvex Loss = 0.0168\n",
      "Test: Same Song Contrastive Loss = 3.6831\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c100893997490995d6d75c3b4148d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5e4950b1ccd49fea8dd18a2c1e3e510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 9] Train: Same Song Contrastive Loss = 3.8947\t|\tConvex Loss = 0.0185\n",
      "Test: Same Song Contrastive Loss = 3.7349\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ad9f5a4324451a9c807e59fe721dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15240042fa1f4df2b6e32f49e50e2069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Train: Same Song Contrastive Loss = 3.8473\t|\tConvex Loss = 0.0182\n",
      "Test: Same Song Contrastive Loss = 3.6189\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec51ed1033154cc6b997fb008b700480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c0e650f3ba4af6af170a63d32aeb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 11] Train: Same Song Contrastive Loss = 3.7842\t|\tConvex Loss = 0.0184\n",
      "Test: Same Song Contrastive Loss = 3.5189\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4b3cc4b7e34bbfb80843ab17bf8474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b62d7ae636464997094e79f32cc950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12] Train: Same Song Contrastive Loss = 3.7285\t|\tConvex Loss = 0.0190\n",
      "Test: Same Song Contrastive Loss = 3.5077\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a47910b56304c80ad5de249dc4dd2b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4fb3861a23649ba8a00d2e5ad7e85fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 13] Train: Same Song Contrastive Loss = 3.6984\t|\tConvex Loss = 0.0197\n",
      "Test: Same Song Contrastive Loss = 3.4208\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98dd3e33864484da5819f9cae52a5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192004374fa94a37be3b28c8fc804e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 14] Train: Same Song Contrastive Loss = 3.6330\t|\tConvex Loss = 0.0186\n",
      "Test: Same Song Contrastive Loss = 3.4065\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e078f9b4bdb742c09d1b18a4a384b727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b228ff123a9449d8e6b82f46b92d8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 15] Train: Same Song Contrastive Loss = 3.6200\t|\tConvex Loss = 0.0184\n",
      "Test: Same Song Contrastive Loss = 3.4683\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c62e021e35941e79e4c9e24b2d1bc40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf68f96c512540af8b16cac82ad8b3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 16] Train: Same Song Contrastive Loss = 3.5992\t|\tConvex Loss = 0.0182\n",
      "Test: Same Song Contrastive Loss = 3.4608\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c1838e47a74798995d20052c4c9fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60b14663a734e8d8aef843862ed44a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 17] Train: Same Song Contrastive Loss = 3.5810\t|\tConvex Loss = 0.0196\n",
      "Test: Same Song Contrastive Loss = 3.4235\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daf86ba18124c25b122b66ea1e8da8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb2710fb22b49a185280f0b59b27cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18] Train: Same Song Contrastive Loss = 3.5725\t|\tConvex Loss = 0.0198\n",
      "Test: Same Song Contrastive Loss = 3.3648\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a404b82e8c1b4cf099c53ef78d3a7cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075077cf351044f684730575d209d2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 19] Train: Same Song Contrastive Loss = 3.4976\t|\tConvex Loss = 0.0185\n",
      "Test: Same Song Contrastive Loss = 3.2795\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527c309ffdc946bd8431e091c3b251ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51362dfaefc44e96a6fe6e3a494fe98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 20] Train: Same Song Contrastive Loss = 3.5154\t|\tConvex Loss = 0.0182\n",
      "Test: Same Song Contrastive Loss = 3.4076\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "346099f5ea424657b454e7f9dac385ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b9be8784da42439b1ff1133013c51e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 21] Train: Same Song Contrastive Loss = 3.4536\t|\tConvex Loss = 0.0181\n",
      "Test: Same Song Contrastive Loss = 3.3897\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b79f25a0b94ea3b0f179d5a24cb87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b46ec114d1442df9d78de8dc46c4a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 22] Train: Same Song Contrastive Loss = 3.4671\t|\tConvex Loss = 0.0187\n",
      "Test: Same Song Contrastive Loss = 3.3301\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2381b3a04c4cb698e5df11659f5d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af57d3ce6e4549e385563e9ee9b761ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 23] Train: Same Song Contrastive Loss = 3.4185\t|\tConvex Loss = 0.0177\n",
      "Test: Same Song Contrastive Loss = 3.2588\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3989f7283c435fa9d3d20560688e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fde32d27c2427db13d72e9fae3f172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24] Train: Same Song Contrastive Loss = 3.4013\t|\tConvex Loss = 0.0201\n",
      "Test: Same Song Contrastive Loss = 3.2063\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e352fb15752471c8ab52706c643c13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5dc380c54d44014ad6ac826dab0fcb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 25] Train: Same Song Contrastive Loss = 3.4044\t|\tConvex Loss = 0.0190\n",
      "Test: Same Song Contrastive Loss = 3.2696\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e173168e87a146c9bbcba6e334020386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f80b662a6464dbd811c33b4a2fd1ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 26] Train: Same Song Contrastive Loss = 3.3803\t|\tConvex Loss = 0.0189\n",
      "Test: Same Song Contrastive Loss = 3.2042\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395a72fece9c4e29911af27c7b677886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda6e9b38726473486bf75f2339bf059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 27] Train: Same Song Contrastive Loss = 3.3471\t|\tConvex Loss = 0.0179\n",
      "Test: Same Song Contrastive Loss = 3.2097\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2facea086abb4782abe6698231570285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c6b2a916b744ed96f57302ac4bd515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 28] Train: Same Song Contrastive Loss = 3.3544\t|\tConvex Loss = 0.0195\n",
      "Test: Same Song Contrastive Loss = 3.1640\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520d8c175fce44a4a06621c690125db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544e50778eb740b6866d869780d71de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 29] Train: Same Song Contrastive Loss = 3.3444\t|\tConvex Loss = 0.0185\n",
      "Test: Same Song Contrastive Loss = 3.1876\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15cc9aa8ef6b499aa33d01198cf71ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1deffb9cce4581bc60f20fa59d1470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30] Train: Same Song Contrastive Loss = 3.3271\t|\tConvex Loss = 0.0187\n",
      "Test: Same Song Contrastive Loss = 3.1781\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa8e75844bf42c9b9db55c923dd7dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c60d731e83b4980a0c90509a289a7f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 31] Train: Same Song Contrastive Loss = 3.3099\t|\tConvex Loss = 0.0189\n",
      "Test: Same Song Contrastive Loss = 3.1334\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c221f0589b844a8840edcdffebb4b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:17<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9824dd9cdf4c2ab14518ef1282ebb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 32] Train: Same Song Contrastive Loss = 3.3109\t|\tConvex Loss = 0.0186\n",
      "Test: Same Song Contrastive Loss = 3.2298\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55180722de4b4bce8e4d70ae0feaed40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:07<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdce902d5ab48a9abee6f3bafb66f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 33] Train: Same Song Contrastive Loss = 3.2747\t|\tConvex Loss = 0.0186\n",
      "Test: Same Song Contrastive Loss = 3.1598\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e7bd683eef4ece9550b38f94d02632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6610e63c6564c5fa178b5b76078db1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 34] Train: Same Song Contrastive Loss = 3.2727\t|\tConvex Loss = 0.0178\n",
      "Test: Same Song Contrastive Loss = 3.1076\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a6e4777fdd4e9eb5d75d378b62e4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:04<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f94eccf6b804916b14d31a9c5836210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 35] Train: Same Song Contrastive Loss = 3.2781\t|\tConvex Loss = 0.0184\n",
      "Test: Same Song Contrastive Loss = 3.1980\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100683572459414996d485b50835e0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:05<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import misc\n",
    "from models.Myna import Myna\n",
    "from training.contrastive_training import train_contrastive\n",
    "\n",
    "model = Myna(\n",
    "    image_size=(128, 256),\n",
    "    channels=1,\n",
    "    patch_size=(16, 16),\n",
    "    latent_space=128,\n",
    "    d_model=384,\n",
    "    depth=12,\n",
    "    heads=6,\n",
    "    mlp_dim=1536,\n",
    "    mask_ratio=0.9,\n",
    "    use_cls=True\n",
    ")\n",
    "\n",
    "#model = torch.load(\"E:\\\\Coding\\\\SongAnalyzer\\\\Analyzer\\\\src\\\\trained_models\\\\Myna-CLS-ASlbum\\\\Epoch-89.pt\", weights_only=False)\n",
    "\n",
    "print(f\"{misc.model_size(model)} Parameters\")\n",
    "train_contrastive(model, test_dataloader, train_dataloader, Config, variational=False, train_masked=True, test_masked=False, album=False, convex=True, start_epoch=0, views=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b985fcedeefba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:29:13.705871Z",
     "start_time": "2025-10-15T21:28:42.509919Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from training.contrastive_training import evaluate_contrastive\n",
    "\n",
    "model.mask_ratio = 0.9\n",
    "same_song_contrastive_loss = evaluate_contrastive(model, test_dataloader, Config, test_masked=False)\n",
    "print(same_song_contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b40ab1336637b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:29:41.828590Z",
     "start_time": "2025-10-15T21:29:13.860902Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from training.contrastive_training import evaluate_contrastive\n",
    "\n",
    "model.mask_ratio = 0.5\n",
    "same_song_contrastive_loss = evaluate_contrastive(model, test_dataloader, Config, test_masked=False)\n",
    "print(same_song_contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea07b222919e84e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:30:14.751780Z",
     "start_time": "2025-10-15T21:29:41.844616Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from training.contrastive_training import evaluate_contrastive\n",
    "\n",
    "model.mask_ratio = 0.25\n",
    "same_song_contrastive_loss = evaluate_contrastive(model, test_dataloader, Config, test_masked=False)\n",
    "print(same_song_contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed9b902789fb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-15T21:30:51.957111Z",
     "start_time": "2025-10-15T21:30:14.775777Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from training.contrastive_training import evaluate_contrastive\n",
    "\n",
    "model.mask_ratio = 0.0\n",
    "same_song_contrastive_loss = evaluate_contrastive(model, test_dataloader, Config, test_masked=False)\n",
    "print(same_song_contrastive_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6af62a7e1524ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from training.autoencoding_training import train_autoencode\n",
    "train_autoencode(model, test_dataloader, train_dataloader, Config, show_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82afdf885f8438",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import IPython\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from datasets import tqdm\n",
    "from training.inference import load_and_parse_audio\n",
    "\n",
    "def test(model):\n",
    "    path = \"E:\\\\SongsDataset\\\\songs\\\\\"\n",
    "    all_folders = os.listdir(path)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for each_song in tqdm(all_folders[100:110]):\n",
    "            song_path = os.path.join(path, each_song)\n",
    "            chunks = load_and_parse_audio(song_path, convert=True, chunk_size=1024).to(\"cuda\")\n",
    "            permuted_chunks = torch.stack([c for c in chunks])\n",
    "\n",
    "            mean = permuted_chunks.mean(dim=[1, 2], keepdim=True)\n",
    "            std = permuted_chunks.std(dim=[1, 2], keepdim=True)\n",
    "\n",
    "            permuted_chunks = (permuted_chunks - mean) / (std + 1e-6)\n",
    "\n",
    "            reconstructed, latent = model(permuted_chunks)\n",
    "\n",
    "            input_tensor = np.concatenate(permuted_chunks.cpu().detach().numpy(), axis=1)\n",
    "            reconstructed = np.concatenate(reconstructed.cpu().detach().numpy(), axis=1)\n",
    "\n",
    "            input_tensor = input_tensor[:, :512]\n",
    "            reconstructed = reconstructed[:, :512]\n",
    "\n",
    "            graph(input_tensor, reconstructed)\n",
    "\n",
    "            S_recon = librosa.feature.inverse.mel_to_stft(reconstructed)\n",
    "            Y_recon = librosa.griffinlim(S_recon)\n",
    "\n",
    "            S_orig = librosa.feature.inverse.mel_to_stft(input_tensor)\n",
    "            Y_orig = librosa.griffinlim(S_orig)\n",
    "\n",
    "            IPython.display.display(IPython.display.Audio(Y_orig, rate=44100))\n",
    "            IPython.display.display(IPython.display.Audio(Y_recon, rate=44100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
