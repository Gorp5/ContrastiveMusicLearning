{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-12T05:18:32.031753Z",
     "start_time": "2025-08-12T05:18:23.599430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from loss.loss_utils import combined_loss\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from models.AudioTransformer import AudioTransformer\n",
    "from data.data_utils import *\n",
    "from models.AudioResnet import AudioResnet\n",
    "from loss.FocalLoss import FocalLoss\n",
    "\n",
    "augmentations = Compose([\n",
    "    AddGaussianNoise(std=0.5),\n",
    "    TimeMasking(max_mask_pct=0.15),\n",
    "    FrequencyMasking(max_mask_pct=0.15),\n",
    "])\n",
    "\n",
    "class Config:\n",
    "    # === General ===\n",
    "\n",
    "    model_name = \"Audio-Transformer-\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float32\n",
    "    save_path = f\"trained_models\\\\{model_name}\\\\\"\n",
    "    seed = 42\n",
    "\n",
    "    # === Training ===\n",
    "    num_classes = 50\n",
    "    num_epochs = 100\n",
    "    batch_size = 1\n",
    "    max_batch_size = 64\n",
    "    learning_rate = 5e-5\n",
    "    min_learning_rate = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "\n",
    "    warmup_threshold = 1.0 / 100.0\n",
    "    step_coefficient = 25.0 / 100.0\n",
    "\n",
    "    gamma = 2.0\n",
    "    save_checkpoints = True\n",
    "\n",
    "    # === Dataset ===\n",
    "    transforms = None\n",
    "    use_masks = True\n",
    "    num_workers = 1\n",
    "    prefetch_factor = 3\n",
    "    val_split = 0.1\n",
    "    shuffle = True\n",
    "    pos_weight = (torch.ones(num_classes) * 10).to(\"cuda\")\n",
    "    criterion = combined_loss"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from data.processing import ParseBalanced\n",
    "\n",
    "directory = \"large-melspec-dataset-top-50-LIBROSA\"\n",
    "data_directory = \"E:/mtg-jamendo/\"\n",
    "subset_file_name = \"autotagging_top50tags\"\n",
    "ParseBalanced(subset_file_name, f\"{data_directory}\", f\"E:/SongsDataset/{directory}\", convert=True, target_per_genre=1300)"
   ],
   "id": "60706242edea8ffb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T05:18:32.417258Z",
     "start_time": "2025-08-12T05:18:32.388824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "large_directory = \"large-melspec-dataset-top-50-LIBROSA\"\n",
    "\n",
    "train_dataset = StreamingSongDataset(f\"E:\\\\SongsDataset\\\\{large_directory}\\\\train_set\\\\data\", f\"E:\\\\SongsDataset\\\\{large_directory}\\\\train_set\\\\genre_labels\", transform=augmentations)\n",
    "test_dataset = StreamingSongDataset(f\"E:\\\\SongsDataset\\\\{large_directory}\\\\test_set\\\\data\", f\"E:\\\\SongsDataset\\\\{large_directory}\\\\test_set\\\\genre_labels\")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.num_workers,\n",
    "    prefetch_factor=Config.prefetch_factor,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=Config.num_workers,\n",
    "    prefetch_factor=Config.prefetch_factor,\n",
    ")"
   ],
   "id": "25b92472f73db5a7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T05:18:32.924136Z",
     "start_time": "2025-08-12T05:18:32.421266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from models.ShortChunkCNN import ShortChunkCNN\n",
    "from utils import misc\n",
    "\n",
    "model = AudioTransformer(latent_space=512, input_dim=128, length=256, num_heads=8, encoder_layers=8, decoder_layers=8, d_model=256, dropout=0.1)\n",
    "print(f\"{misc.model_size(model)} Parameters\")"
   ],
   "id": "b699c79369ea9dfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77884800 Parameters\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-12T05:18:32.987817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from training.autoencoding_training import train_autoencode\n",
    "train_autoencode(model, test_dataloader, train_dataloader, Config, show_graph=False)"
   ],
   "id": "bb6af62a7e1524ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "aa3bc1cfbd0cd5ac"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
