{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T08:03:26.871841Z",
     "start_time": "2025-11-12T08:03:26.826323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import subprocess\n",
    "\n",
    "from anyio import sleep\n",
    "\n",
    "def cluster_elki(name, num_clusters):\n",
    "    # Define parameters\n",
    "    elki_jar = \"elki-bundle-0.8.0.jar\"\n",
    "    data_file = f\"output_analysis/output-{name}.csv\"\n",
    "\n",
    "    cmd = [\n",
    "        \"java\", \"-jar\", elki_jar,\n",
    "        \"KDDCLIApplication\",\n",
    "        \"-dbc.in\", data_file,\n",
    "        \"-algorithm\", \"clustering.hierarchical.extraction.CutDendrogramByNumberOfClusters\",\n",
    "        \"-algorithm\", \"Anderberg\",\n",
    "        \"-algorithm.distancefunction\", \"CosineDistance\",\n",
    "        \"-hierarchical.minclusters\", str(num_clusters),\n",
    "        \"-resulthandler\", \"ResultWriter\",\n",
    "        \"-out.gzip\", \"false\",\n",
    "        \"-out\", f\"output_analysis/elki-TEST-{name}-{num_clusters}\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"An error occurred:\\n\", e.stderr)"
   ],
   "id": "6ab21de71dbc50c2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T08:04:43.284457Z",
     "start_time": "2025-11-12T08:03:47.127967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from training.inference import load_and_parse_audio\n",
    "from mutagen.easyid3 import EasyID3\n",
    "\n",
    "def process_song(song_path, chunking=True, chunk_size=256):\n",
    "    chunks = load_and_parse_audio(song_path, convert=True, chunking=chunking, chunk_size=chunk_size)\n",
    "    song_easyID3 = EasyID3(song_path)\n",
    "    url_from_albumartist = song_easyID3.get(\"albumartist\", [None])[0]\n",
    "\n",
    "    id = url_from_albumartist.split(\"/\")[-1]\n",
    "    return id, chunks\n",
    "\n",
    "def compute(model, name, batch_size=1, num_workers=4, chunking=True, chunk_size=256, start_partition=1):\n",
    "    path = \"E:\\\\SongsDataset\\\\songs\\\\\"\n",
    "    all_songs = os.listdir(path)\n",
    "    if start_partition == 1:\n",
    "        sign = 'w'\n",
    "    else:\n",
    "        sign = 'a'\n",
    "\n",
    "    with open(name, sign, encoding=\"utf-8\") as f, torch.no_grad(), ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # submit all preprocessing jobs\n",
    "        partitions = 8\n",
    "        num_songs = len(all_songs) // partitions\n",
    "        for index in range(start_partition, partitions):\n",
    "            futures = [executor.submit(process_song, os.path.join(path, song), chunking, chunk_size) for song in all_songs[(index - 1) * num_songs:index * num_songs]]\n",
    "\n",
    "            # process results in batches of X\n",
    "            for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "                song_path, chunks = future.result()\n",
    "                if chunks is None:\n",
    "                    continue\n",
    "\n",
    "                run_batch(model, chunks, f, song_path)\n",
    "\n",
    "\n",
    "def compute_async(model, name, batch_size=1, num_workers=4, chunking=True, chunk_size=256, start_partition=1):\n",
    "    path = \"E:\\\\SongsDataset\\\\songs\\\\\"\n",
    "    all_songs = os.listdir(path)\n",
    "    if start_partition == 1:\n",
    "        sign = 'w'\n",
    "    else:\n",
    "        sign = 'a'\n",
    "\n",
    "    with open(name, sign, encoding=\"utf-8\") as f, torch.no_grad(), ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        # submit all preprocessing jobs\n",
    "        partitions = 8\n",
    "        num_songs = len(all_songs) // partitions\n",
    "        index = 1\n",
    "\n",
    "        for song in tqdm(all_songs):\n",
    "            song_path, chunks = process_song(os.path.join(path, song), chunking, chunk_size)\n",
    "            if chunks is None:\n",
    "                continue\n",
    "\n",
    "            run_batch(model, chunks, f, song_path)\n",
    "\n",
    "def run_batch(model, chunks, file_handle, song_path, max_memory=32):\n",
    "    chunks = chunks.to(\"cuda\")\n",
    "\n",
    "    chunks = chunks.unsqueeze(1)\n",
    "\n",
    "    length = chunks.shape[-1]\n",
    "    max_batch_size = 67108864 // (length ** 2)\n",
    "\n",
    "    num_chunks = int(chunks.shape[0] / max_batch_size)\n",
    "\n",
    "    if num_chunks <= 1:\n",
    "        data_minibatches = [chunks]\n",
    "    else:\n",
    "        data_minibatches = torch.chunk(chunks, num_chunks, dim=0)\n",
    "\n",
    "    all_preds = []\n",
    "\n",
    "    for i, batch in enumerate(data_minibatches):\n",
    "        data_minibatch = batch\n",
    "        outputs = model(data_minibatch)\n",
    "        all_preds.extend(outputs.cpu())\n",
    "\n",
    "    if len(all_preds) == 0:\n",
    "        print(f\"Empty Song\")\n",
    "        return\n",
    "\n",
    "    latents = torch.stack(all_preds, dim=0)\n",
    "    averages = latents.mean(dim=0).numpy()\n",
    "    torch.cuda.empty_cache()\n",
    "    line = \" \".join([str(x) for x in averages]) + f\" \\\"{os.path.basename(song_path)}\\\"\\n\"\n",
    "    file_handle.write(line)"
   ],
   "id": "5171d48bce862e2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T08:05:08.980266Z",
     "start_time": "2025-11-12T08:04:43.289505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper for loading older model versions\n",
    "def add_fields(model, use_sinusoidal=False, use_y_emb=False,\n",
    "               use_rope_x=False, use_rope_y=False, rope_base=-1,\n",
    "               use_alibi_x=False, use_alibi_y=False):\n",
    "\n",
    "    model.use_cls = True\n",
    "    model.predict_tempo = False\n",
    "    model.use_sinusoidal = use_sinusoidal\n",
    "    model.use_y_emb = use_y_emb\n",
    "    model.use_rope_x = use_rope_x\n",
    "    model.use_rope_y = use_rope_y\n",
    "    model.rope_base = rope_base\n",
    "    model.use_alibi_x = use_alibi_x\n",
    "    model.use_alibi_y = use_alibi_y\n",
    "    model.needs_coordinates = use_rope_x or use_rope_y or use_alibi_x or use_alibi_y\n",
    "    if not (use_alibi_x or use_alibi_y):\n",
    "        model.transformer.alibi_2d = None\n",
    "\n",
    "    return model"
   ],
   "id": "69ca15c44b700647",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T23:53:43.168836Z",
     "start_time": "2025-11-04T23:53:42.971341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torch.load(\"E:\\\\Coding\\\\SongAnalyzer\\\\Analyzer\\\\src\\\\final-models\\\\Myna-1D-ALIBI-256L-0.9M\\\\1d_alibi_Epoch-511.pt\", weights_only=False)\n",
    "model.mask_ratio = 0.0\n",
    "model = model.to(\"cuda\")\n",
    "model = add_fields(model, use_y_emb=True, use_alibi_x=True)"
   ],
   "id": "1396a8efcf2e13d",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:49:25.619216Z",
     "start_time": "2025-11-05T04:39:29.723968Z"
    }
   },
   "cell_type": "code",
   "source": "compute_async(model, \"E:/Coding/SongAnalyzer/Analyzer/src/output_analysis/output-Myna-CLS-ALIBI-1D-Chunking-256.csv\", chunking=True, chunk_size=256)",
   "id": "84fb49cf0914a7cc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7056/7056 [2:09:55<00:00,  1.10s/it]  \n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-05T06:49:36.773664Z",
     "start_time": "2025-11-05T06:49:25.918102Z"
    }
   },
   "cell_type": "code",
   "source": "cluster_elki(\"Myna-CLS-ALIBI-1D-Chunking-256\", 256)",
   "id": "8db5f46ab4a1b95f",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "compute_async(model, \"E:/Coding/SongAnalyzer/Analyzer/src/output_analysis/output-Myna-CLS-ALIBI-1D-Chunking-256.csv\",\n",
    "              chunking=True, chunk_size=256)"
   ],
   "id": "dfe3dfd43d29f528"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T05:57:53.080058Z",
     "start_time": "2025-11-23T05:57:53.073520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_cluster_file_name(file_path):\n",
    "    ids = []\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            start = line[:2]\n",
    "            if start == \"ID\":\n",
    "                id = line.split(\" \")[-1][:-1]\n",
    "                ids.append(id)\n",
    "\n",
    "    return ids\n",
    "\n",
    "def parse_cluster_file_data(file_path):\n",
    "    ids = []\n",
    "    labels = []\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.split(\"\\\"\")\n",
    "            data = parts[0]\n",
    "            label = parts[1]\n",
    "\n",
    "            data = data.split(\" \")\n",
    "            data = torch.tensor([float(d) for d in data[:-1]])\n",
    "            ids.append(data)\n",
    "            labels.append(label)\n",
    "\n",
    "    return torch.stack(ids, dim=0), labels"
   ],
   "id": "a96e90a092bcfcc8",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T05:57:46.386677Z",
     "start_time": "2025-11-23T05:57:46.193222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from spotipy import SpotifyException\n",
    "from asyncio import wait\n",
    "from spotipy.oauth2 import SpotifyOAuth\n",
    "\n",
    "import spotipy\n",
    "import os\n",
    "\n",
    "with open(\"spotify-info.txt\") as file:\n",
    "    lines = file.readLines()\n",
    "    CLIENT_ID = lines[0]\n",
    "    CLIENT_SECRET = lines[1]\n",
    "    REDIRECT_URI = lines[2]\n",
    "\n",
    "# We'll need all of these permissions\n",
    "scope = \"user-read-private playlist-read-private playlist-modify-private user-library-modify\"\n",
    "\n",
    "sp = spotipy.Spotify(\n",
    "    auth_manager=SpotifyOAuth(\n",
    "        client_id=CLIENT_ID,\n",
    "        client_secret=CLIENT_SECRET,\n",
    "        redirect_uri=REDIRECT_URI,\n",
    "        scope=scope\n",
    "    )\n",
    ")\n",
    "\n",
    "user = sp.current_user()\n",
    "print(\"User ID:\", user[\"id\"])\n",
    "print(\"Display Name:\", user[\"display_name\"])\n",
    "print(\"Email:\", user.get(\"email\"))\n",
    "print(\"Profile URL:\", user[\"external_urls\"][\"spotify\"])\n",
    "\n",
    "def safe_add_items(playlist_id, items, max_retries=5):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            sp.playlist_add_items(playlist_id, items)\n",
    "            return True\n",
    "        except SpotifyException as e:\n",
    "            if e.http_status in [429, 502, 503, 504]:\n",
    "                retry_after = int(e.headers.get(\"Retry-After\", 2 ** attempt))\n",
    "                print(f\"Rate limited or gateway error, retrying in {retry_after}s...\")\n",
    "                wait(retry_after)\n",
    "            else:\n",
    "                raise\n",
    "    raise RuntimeError(\"Max retries reached while adding items to playlist.\")\n",
    "\n",
    "def create_playlist(path_file, name, track_ids=None):\n",
    "    playlist = sp.user_playlist_create(\n",
    "        user=user[\"id\"],\n",
    "        name=f\"Clustering / {name}\",\n",
    "        public=True,\n",
    "        description=\"Created via the Spotify API!\"\n",
    "    )\n",
    "\n",
    "    playlist_id = playlist[\"id\"]\n",
    "    print(\"Created playlist:\", playlist[\"external_urls\"][\"spotify\"])\n",
    "\n",
    "    if track_ids is None:\n",
    "        track_ids = parse_cluster_file_name(path_file)\n",
    "\n",
    "    for i in range(0, len(track_ids), 100):\n",
    "        sp.playlist_add_items(playlist_id, track_ids[i:i+100])\n",
    "\n",
    "    print(\"Tracks added successfully!\")"
   ],
   "id": "1747662bcdebc863",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: g47dvcltndgtgav7sgqsia10p\n",
      "Display Name: Gorp\n",
      "Email: potatoeunbeatable@gmail.com\n",
      "Profile URL: https://open.spotify.com/user/g47dvcltndgtgav7sgqsia10p\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "mpl.rcParams['mathtext.default'] = 'regular'\n",
    "\n",
    "def safe_label(s):\n",
    "    for ch in ['$', '^', '_', '{', '}', '#', '%', '&']:\n",
    "        s = s.replace(ch, f'\\\\{ch}')\n",
    "    return s\n",
    "\n",
    "# Needs at least one point for each dimension in song vectors.\n",
    "# Solution could be to generate similar embeddings by adding *very small* amounts of random noise?\n",
    "# Worth looking into\n",
    "def get_similarity_hull(data, labels, interested_ids, k=100):\n",
    "    length = len(interested_ids)\n",
    "    if length == 0:\n",
    "        return\n",
    "\n",
    "    index = [i for i, x in enumerate(labels) if x in interested_ids]\n",
    "    hull_points = data[index]\n",
    "\n",
    "    hull = ConvexHull(hull_points)\n",
    "\n",
    "    A = hull.equations[:, :-1]  # normals\n",
    "    b = hull.equations[:, -1]   # offsets\n",
    "    A = torch.tensor(A, dtype=torch.float32)\n",
    "    b = torch.tensor(b, dtype=torch.float32)\n",
    "\n",
    "    def hull_space(points):\n",
    "        normA = torch.linalg.norm(A, dim=1)\n",
    "\n",
    "        signed = (points @ A.T + b) / normA\n",
    "\n",
    "        depth = -torch.max(signed, dim=1).values\n",
    "\n",
    "        return depth\n",
    "\n",
    "    def mahalanobis(points):\n",
    "        mean = hull_points.mean(axis=0, dtype=float)\n",
    "        cov = np.cov(points, rowvar=False, dtype=float)\n",
    "        inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "        diffs = points - mean\n",
    "\n",
    "        d2 = np.einsum('ni,ij,nj->n', diffs, inv_cov, diffs)\n",
    "        distances = np.sqrt(d2)\n",
    "\n",
    "        return np.exp(-distances)\n",
    "\n",
    "    return get_k_most_similar_maha(data, labels, hull_space, k=k)\n",
    "\n",
    "\n",
    "def cosine_sim(track_data, interested_point):\n",
    "    track_norm = F.normalize(track_data, p=2, dim=1)\n",
    "    point_norm = F.normalize(interested_point, p=2, dim=1)\n",
    "    similarity_matrix = track_norm @ point_norm.T\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def get_k_most_similar_maha(data, labels, maha_dist, k=100):\n",
    "    similarity_matrix = maha_dist(data)\n",
    "    sim_tensor = torch.Tensor(similarity_matrix)\n",
    "    sorted_x, indices = torch.sort(sim_tensor, dim=0, descending=True)\n",
    "\n",
    "    np_labels = np.array(labels)\n",
    "    sim_labels = np_labels[indices.numpy()]\n",
    "\n",
    "    top_k = k\n",
    "    if len(sorted_x) > (top_k):\n",
    "        sim_labels_trunc = sim_labels[:top_k]\n",
    "    else:\n",
    "        sim_labels_trunc = sim_labels\n",
    "\n",
    "    sim_labels_trunc = [str(x) for x in sim_labels_trunc]\n",
    "\n",
    "    for label in sim_labels_trunc:\n",
    "        print(label)\n",
    "\n",
    "    return sim_labels_trunc\n",
    "\n",
    "\n",
    "def get_k_most_similar(data, labels, point, k=100):\n",
    "    track_data = data\n",
    "\n",
    "    similarity_matrix = cosine_sim(track_data, point)\n",
    "    ids = np.array(labels)\n",
    "\n",
    "    # Sort similarities per song\n",
    "    similarity_matrix = similarity_matrix.mean(dim=1)\n",
    "    sorted_x, indices = torch.sort(similarity_matrix, dim=0, descending=True)\n",
    "\n",
    "    # Plot for each selected song\n",
    "    sim_values = sorted_x.cpu().numpy()\n",
    "    sim_labels = ids[indices.cpu().numpy()]\n",
    "\n",
    "    top_k = k\n",
    "    if len(sim_values) > (top_k):\n",
    "        sim_labels_trunc = sim_labels[:top_k]\n",
    "    else:\n",
    "        sim_labels_trunc = sim_labels\n",
    "\n",
    "    sim_labels_trunc = [str(x) for x in sim_labels_trunc]\n",
    "\n",
    "    for label in sim_labels_trunc:\n",
    "        print(label)\n",
    "\n",
    "    return sim_labels_trunc\n",
    "\n",
    "def parse_data(path_file, songs_to_display=[1]):\n",
    "    track_data, ids = parse_cluster_file_data(path_file)\n",
    "\n",
    "    # Normalize embeddings to unit length\n",
    "    track_norm = F.normalize(track_data, p=2, dim=1)\n",
    "\n",
    "    # Compute cosine similarity matrix\n",
    "    similarity_matrix = track_norm @ track_norm.T  # [N, N]\n",
    "    ids = np.array(ids)\n",
    "\n",
    "    # Sort similarities per song\n",
    "    sorted_x, indices = torch.sort(similarity_matrix, descending=True)\n",
    "\n",
    "    # Plot for each selected song\n",
    "    for song_idx in songs_to_display:\n",
    "        sim_values = sorted_x[song_idx].cpu().numpy()\n",
    "        sim_labels = ids[indices[song_idx].cpu().numpy()]\n",
    "\n",
    "        ref_song_id = ids[song_idx]\n",
    "        ref_pos = np.where(sim_labels == ref_song_id)[0][0]\n",
    "\n",
    "        # Truncate to top 250 + bottom 250\n",
    "        top_k, bottom_k = 250, 250\n",
    "        if len(sim_values) > (top_k + bottom_k):\n",
    "            sim_values_trunc = np.concatenate((sim_values[:top_k], sim_values[-bottom_k:]))\n",
    "            sim_labels_trunc = np.concatenate((sim_labels[:top_k], sim_labels[-bottom_k:]))\n",
    "        else:\n",
    "            sim_values_trunc = sim_values\n",
    "            sim_labels_trunc = sim_labels\n",
    "\n",
    "        # Check if reference is visible\n",
    "        ref_in_range = np.where(sim_labels_trunc == ref_song_id)[0]\n",
    "        ref_in_range = ref_in_range[0] if len(ref_in_range) > 0 else None\n",
    "\n",
    "        plt.figure(figsize=(2.2, len(sim_values_trunc) * 0.25), dpi=150)\n",
    "        plt.imshow(sim_values_trunc[:, None], cmap='viridis', aspect='auto', interpolation='none')\n",
    "\n",
    "        # Highlight reference song\n",
    "        if ref_in_range is not None:\n",
    "            plt.axhline(ref_in_range, color='red', linewidth=1.2)\n",
    "            plt.text(0.5, ref_in_range, f\"← {ref_song_id}\", color='red', fontsize=7,\n",
    "                     va='center', ha='left', transform=plt.gca().transData)\n",
    "\n",
    "        # Add text showing similarity values to the right\n",
    "        ax = plt.gca()\n",
    "        for i, val in enumerate(sim_values_trunc):\n",
    "            ax.text(1.05, i, f\"{val:.3f}\", color='white', fontsize=6, va='center',\n",
    "                    transform=ax.transData)\n",
    "\n",
    "        # Format y labels safely\n",
    "        plt.yticks(np.arange(len(sim_labels_trunc)), [safe_label(lbl) for lbl in sim_labels_trunc], fontsize=6)\n",
    "        plt.xticks([])\n",
    "        plt.title(f\"Similarity to song {safe_label(ref_song_id)}\", fontsize=10, pad=10)\n",
    "        plt.colorbar(label=\"Cosine similarity\", shrink=0.7)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ],
   "id": "853ca9b05f367c25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Playlist generation example on a specific song",
   "id": "9c8226eafcd4d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T05:57:56.973718Z",
     "start_time": "2025-11-23T05:57:56.557195Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"E:/Coding/SongAnalyzer/Analyzer/src/output_analysis/output-Myna-CLS-ALIBI-1D-Chunking-256.csv\"\n",
    "track_data, ids = parse_cluster_file_data(path)"
   ],
   "id": "3f34faa741710d5d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T06:02:02.937034Z",
     "start_time": "2025-11-23T06:02:02.337695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path = \"E:/Coding/SongAnalyzer/Analyzer/src/output_analysis/output-Myna-CLS-ALIBI-1D-Chunking-256.csv\"\n",
    "label = [\"0XOMAi1bTq6FLANw5WUzKr\"]\n",
    "\n",
    "index = [i for i, x in enumerate(ids) if x in label]\n",
    "interested_point = track_data[index]\n",
    "\n",
    "most_sim = get_k_most_similar(track_data, ids, interested_point, k=114)\n",
    "create_playlist(None, \"Reflective Summer\", most_sim)"
   ],
   "id": "5d3d3867ba9b94ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0XOMAi1bTq6FLANw5WUzKr\n",
      "07piOqPFq7X0BtdFlodEPe\n",
      "0QbvYVhykr3lx0iOvr1DYd\n",
      "0XpJIpi9bLnV2UbjZ6nV9g\n",
      "3v0eRsjxQcCJfHINOyX7sZ\n",
      "7wxWlTpMjpF2ztYFePpIXp\n",
      "0WaaPFt4Qy8sVfxKz43bCD\n",
      "0DMDOM5l1aYm18rR214KbP\n",
      "6zRxzFCzowTo6TAzI3dHCC\n",
      "0Qv7xi6uPSqH2k82tOkGSt\n",
      "6Vjm8aQFfuNmm7jwgCbAoW\n",
      "16doMTberqpHTGc467rJBw\n",
      "68AzhSmdueBmCUaVG2mOwv\n",
      "4mh0rIKPBhMBAln7t3m0Zk\n",
      "2a1iMaoWQ5MnvLFBDv4qkf\n",
      "7upG8kgnfF4yfaOGNKHXJg\n",
      "5pTD57jhRgNbpyVCHsQvkv\n",
      "0awZwmlC6pxH65KTZpadmX\n",
      "0dMTCCAYuGPNHGeaN6s9P3\n",
      "0ytsgfXzI3NlpHVnBGKJNn\n",
      "26AYR77170U49cMcXB7aRV\n",
      "596IkZP89HvFYdgOb3lNvP\n",
      "1YrU8ExqF04ygegVoOOoFU\n",
      "1PJRDeZSoZk7gtisdTYfLi\n",
      "2cDI4xiUEkAgp3gI9iIMk4\n",
      "0y8uWWRKZrJgbsfy1oUOeF\n",
      "7MdKQKCcCxu5rLeD8H6tsu\n",
      "3PfOVqpFVBxf39Qxj6Vs6l\n",
      "5g7FVko9msJrVqpZlmFmUU\n",
      "3IbX1Ycd2PD7jwb3rWRX4o\n",
      "21wC5i3a5qEEPpXn3hXt8V\n",
      "3zBeDk1Ijt11UkVYaDNHFk\n",
      "1BvYBXJHCXowsLQ9ZYsCPA\n",
      "0cnOTTEREe2gKR9ZkZXeQS\n",
      "4PVrz6sCGjxzNxMw729FVn\n",
      "6WhoGqTFLJGCgMNUyBDzt5\n",
      "4ptIWfbb32M6vftqhyt9CK\n",
      "5UWwZ5lm5PKu6eKsHAGxOk\n",
      "5ISHFvPLUqKz2JfDRtwnb2\n",
      "2xHu33sRZaQ3T725emVgbA\n",
      "1YylK4wwCYiUp1Dv8T2lix\n",
      "76xIJEP0Fu7ae5PuzR0XG6\n",
      "1bQu3S9Au6lY3RQ9TbxL3R\n",
      "6p03ssQvEzWVSQxGGyJIML\n",
      "3DobVJTo6VvNZ5nludezy6\n",
      "4brcDnr3UIVYqPZuGB95JB\n",
      "3XZo49fN68s54wUsSVy21H\n",
      "6WBhtVJxkqFScHHLFaZcmG\n",
      "0aHGWWgi4JuJUWF3zm8h50\n",
      "12Ug3wAwvySmAx9WMbGkPb\n",
      "6sUbqAppyWJCIBoeUw8u64\n",
      "4pRmoszVyK7kEjXqWqdd2j\n",
      "4YVcnFE6Ayx2Ypz58TYIaQ\n",
      "1pNUmVxDiE8t6P1XxcZAv8\n",
      "187dD6DIkKRel2H9XfimYz\n",
      "0wNR01ZZBPtPnyHOvFK5mB\n",
      "5ZRNaqIMyAQJzU22W8VM40\n",
      "0XsYtBBHa8w1fILTicDL1T\n",
      "33iv3wnGMrrDugd7GBso1z\n",
      "7cr1SmfYSZopE80WM3jEpv\n",
      "1x0NfY1A4q8eKN3k4X8sfE\n",
      "5raBZWODW8fQRuF0hA2rXw\n",
      "3nS9R3c91Hg6Sux5DGqOKI\n",
      "59bjmepUO1EdKaMaIpW5BG\n",
      "1cQq7fC8cELbsxh7nNUFes\n",
      "2BLYOkLHmhY255IQCyW7sO\n",
      "22E2QiTocW1X5gPzQrq5ed\n",
      "2ydUT1pFhuLDnouelIv4WH\n",
      "0F71fi3l7LfFzRUaCov7Gq\n",
      "6MSjqrE3gIToK8qiQIBf18\n",
      "7mwLlFNlWD4AOFoxPJTPwn\n",
      "4aTIqnMuLzWThIrT41eCk3\n",
      "0bePGTDjn0XuEKoN7rOMvV\n",
      "1c49OEAcGZQfwIu3RoYcOP\n",
      "1zFbBrZmJr1Z49HYe84dBg\n",
      "0DgEjzl2zd8Fuj9yPjpEfq\n",
      "4HeW5pD6xCu7GpvxIp1P3q\n",
      "0SyDN2bmZtpM5Kr0y1DE6G\n",
      "2IQJRs4FRcOlJsuLxIWJbu\n",
      "5LusDHzggVu5HI1Gn8awRN\n",
      "0MSqR4unoY5KReMoOP6E2D\n",
      "0Knzb4bQGM1FFe1RZDNebF\n",
      "40L3j5BHvEGz8hcNdJTtpB\n",
      "6jdvtVKYwcq2zAme6TdlMe\n",
      "3gkDGTYetFjVfJr85iUDJk\n",
      "00B50iRsMgiInIgrF1Gg79\n",
      "6LOiwTV7SEO1zJc1BOJMwT\n",
      "3aXSCmnTPMhQdUnDkVuNuj\n",
      "6Ld0jTImMWx6C5l7i1MlZI\n",
      "7e6QeT9RzpVsWktf5HLM7K\n",
      "5AwTV81y6vH0vnXqW9Trll\n",
      "78R5rt4GcC9tzpEtTWjlp9\n",
      "19QFxKRyymoYB5QocFbqPy\n",
      "27JtieswTsVws6hfYqLQ7S\n",
      "1ddbXmQrRRoUesptGvmDay\n",
      "0XRlCDp99MEaPDRWTUXmep\n",
      "1mv48X9a1vrlRX6WDYwpA3\n",
      "7wnW4ypiBD2GCfjkzZp2RH\n",
      "5ymyfnX8QMt5MAaMhZROb3\n",
      "2OyO7GySf9DytV2hU2tnK6\n",
      "2TnDcyhv3b9liArwgM58ko\n",
      "5ynO8cYFjDwELIZfFHHeYe\n",
      "6MyZDt84pg8y8ySGXFiOzz\n",
      "4pVaOPygeSnR6iwzdxWdnd\n",
      "2Lumsra3kuU61wXkEKzKaK\n",
      "0AW1rOPY2P7XJfELS89Rud\n",
      "5e49INy8CAmgvqU7H8n9C6\n",
      "7ETijvgUdK7rBlGfvhiWQj\n",
      "6GG73Jik4jUlQCkKg9JuGO\n",
      "4gedOBx5StsjhlWTjG0Q9g\n",
      "1hizUMxwkjhEKOO6arubUn\n",
      "6ZMeVIV4NSBEOUI9VKRNYX\n",
      "1YrnDTqvcnUKxAIeXyaEmU\n",
      "1sRuxHGe5UHBzZdUKWp2MN\n",
      "Created playlist: https://open.spotify.com/playlist/1FxSx7pMMnhFVzL4iiviCr\n",
      "Tracks added successfully!\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T15:26:37.651817Z",
     "start_time": "2025-11-20T15:26:37.030238Z"
    }
   },
   "cell_type": "code",
   "source": "create_playlist(None, \"Ambient-Trance\", most_sim)",
   "id": "fb2dcdffc5cbdbc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created playlist: https://open.spotify.com/playlist/2J6sswkJYt600TjP6X1mC0\n",
      "Tracks added successfully!\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
