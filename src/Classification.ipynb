{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from datasets import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from torchvision.models import resnet101\n",
    "\n",
    "from data.procesing import StreamingSongDataset"
   ],
   "id": "3e956a6332012f5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from data.procesing import ParseData\n",
    "\n",
    "ParseData(\"raw_30s_cleantags_125artists\", \"E:/SongsDataset/raw_30s_melspecs/\", \"E:/SongsDataset/balanced-melspec-dataset/\", features=96, chunks_per_batch=4096, chunk_size=256, chunks_per_song=16, songs_per_label, per_label=325)"
   ],
   "id": "e8521052fdfd9f88",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,  # Already shuffled\n",
    "    num_workers=6,\n",
    "    prefetch_factor=6,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=True,  # Already shuffled\n",
    "    num_workers=6,\n",
    "    prefetch_factor=6,\n",
    ")"
   ],
   "id": "193cfb7b29fd3253",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "class Config:\n",
    "    # === General ===\n",
    "    model_name = \"Resnet-Classifier-MEL\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dtype = torch.float32\n",
    "    save_path = f\"trained_models\\\\{model_name}\\\\\"\n",
    "    seed = 42\n",
    "\n",
    "    # === Training ===\n",
    "    num_epochs = 30\n",
    "    batch_size = 24\n",
    "    learning_rate = 1e-4\n",
    "    weight_decay = 1e-4\n",
    "    warmup_percent = 0.15\n",
    "    max_grad_norm = 1.0\n",
    "    log_every = 10  # steps between logs (optional)\n",
    "    save_checkpoints = True\n",
    "\n",
    "    # === Dataset ===\n",
    "    use_masks = True\n",
    "    num_workers = 4\n",
    "    val_split = 0.2\n",
    "    shuffle = True\n",
    "\n",
    "    # === Model Behavior ===\n",
    "    class_ratio = torch.tensor(ratios).to(device=\"cuda\")"
   ],
   "id": "3a59218b374f209f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.optim\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "def train(model, test_dataloader, train_dataloader, config):\n",
    "    # Training setup\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=config.class_ratio)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)  # L2 regularization\n",
    "    model.to(\"cuda\", config.dtype)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(40):\n",
    "        train_loss_total = 0\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.squeeze(0).unsqueeze(1).to(\"cuda\", config.dtype)\n",
    "            labels = labels.squeeze(0).to(\"cuda\", config.dtype)\n",
    "\n",
    "            num_chunks = int(inputs.shape[0] / config.batch_size) + 1\n",
    "\n",
    "            data_minibatches = torch.chunk(inputs, num_chunks, dim=0)\n",
    "            label_minibatches = torch.chunk(labels, num_chunks, dim=0)\n",
    "\n",
    "            for i, (data_minibatch, label_minibatch) in enumerate(zip(data_minibatches, label_minibatches)):\n",
    "                outputs = model(data_minibatch)\n",
    "                loss = criterion(outputs, label_minibatch)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                train_loss_total += loss.item()\n",
    "\n",
    "        # test_loss_average, all_preds, all_labels = eval(model, test_dataloader, criterion, config)\n",
    "        #\n",
    "        # precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
    "        # recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
    "        # f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "        train_loss_average = train_loss_total / len(train_dataloader)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Train Loss: {train_loss_average:.4f}\")\n",
    "        # print(f\"Epoch {epoch + 1}, Test Loss: {test_loss_average:.4f}\")\n",
    "        #print(f\"Test Accuracy: {correct / total:.2%}\")\n",
    "        # print(f\"Precision: {precision_macro:.4f}\\t Recall: {recall_macro:.4f}\\t F1: {f1_macro:.4f}\")\n",
    "\n",
    "        torch.save(model, f\".\\\\{config.save_path}\\\\Classifier-Epoch-{epoch + 1}.pt\")\n",
    "\n",
    "\n",
    "def eval(model, dataloader, criterion, config):\n",
    "    test_loss_total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            inputs, labels = batch\n",
    "\n",
    "            inputs = inputs.squeeze(0).unsqueeze(1).to(\"cuda\", config.dtype)\n",
    "            labels = labels.squeeze(0).to(\"cuda\", config.dtype)\n",
    "\n",
    "            num_chunks = int(inputs.shape[0] / config.batch_size) + 1\n",
    "\n",
    "            data_minibatches = torch.chunk(inputs, num_chunks, dim=0)\n",
    "            label_minibatches = torch.chunk(labels, num_chunks, dim=0)\n",
    "\n",
    "            for i, (data_minibatch, label_minibatch) in enumerate(zip(data_minibatches, label_minibatches)):\n",
    "                outputs = model(data_minibatch)\n",
    "                loss = criterion(outputs, label_minibatch)\n",
    "\n",
    "                test_loss_total += loss.item()\n",
    "\n",
    "                all_preds.extend(outputs.sigmoid().cpu().numpy())\n",
    "                all_labels.extend(label_minibatch.cpu().numpy())\n",
    "\n",
    "    return test_loss_total / len(dataloader), all_preds, all_labels\n",
    "\n",
    "def model_size(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ],
   "id": "6c9dfd3f464f3a47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.ShortChunkCNN import ShortChunkCNN\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "model = ShortChunkCNN(n_channels=128, n_class=50)\n",
    "\n",
    "print(f\"Parameters: {model_size(model)}\")\n",
    "train(model, None, train_dataloader, Config)"
   ],
   "id": "4f8b8c2ae5dbf53d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.BCEWithLogitsLoss(pos_weight=Config.class_ratio)\n",
    "test_loss_average, all_probs, all_labels = eval(model, train_dataloader, criterion, Config)\n",
    "\n",
    "all_p_tensor = torch.stack([torch.tensor(x) for x in all_probs], dim=0).float()\n",
    "all_l_tensor = torch.stack([torch.tensor(x) for x in all_labels], dim=0).int()"
   ],
   "id": "492572a11f4f3613",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def graph(probs, labels):\n",
    "    # Store per-threshold values\n",
    "    thresholds = np.linspace(0, 1, 200)\n",
    "    precision_all = []\n",
    "    recall_all = []\n",
    "\n",
    "    for class_idx in range(probs.shape[1]):\n",
    "        y_true = labels[:, class_idx]\n",
    "        y_score = probs[:, class_idx]\n",
    "\n",
    "        precision, recall, thresh = precision_recall_curve(y_true, y_score)\n",
    "\n",
    "        # Interpolate to get precision/recall at uniform thresholds\n",
    "        interp_precision = np.interp(thresholds, thresh, precision[:-1])  # precision[:-1] because it's len(thresh)+1\n",
    "        interp_recall = np.interp(thresholds, thresh, recall[:-1])\n",
    "\n",
    "        precision_all.append(interp_precision)\n",
    "        recall_all.append(interp_recall)\n",
    "\n",
    "    # Average across all classes\n",
    "    precision_mean = np.mean(precision_all, axis=0)\n",
    "    recall_mean = np.mean(recall_all, axis=0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(thresholds, precision_mean, label='Precision')\n",
    "    plt.plot(thresholds, recall_mean, label='Recall')\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Precision and Recall vs Threshold (Macro-Averaged over Genres)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "44d6b5cf2e0aaaac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph(all_p_tensor, all_l_tensor)",
   "id": "9ef9b87ae2110695",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(all_p_tensor.ravel(), bins=100)\n",
    "plt.title(\"Histogram of predicted genre probabilities\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ],
   "id": "a25278c900319164",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def toMEL(wv, sr):\n",
    "    spec = librosa.feature.melspectrogram(y=wv, sr=sr)\n",
    "    spec = librosa.amplitude_to_db(spec, ref=np.max)\n",
    "    return spec\n",
    "\n",
    "def process_song(song_path, folder_in, folder_out, transform):\n",
    "    latents_path_name = os.path.join(folder_out, song_path[:-4] + \".npy\")\n",
    "\n",
    "    if os.path.exists(latents_path_name):\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        wv, sr = librosa.load(os.path.join(folder_in, song_path), sr=44100)\n",
    "        latent_space = transform(wv, sr)\n",
    "        np.save(latents_path_name, latent_space)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {song_path}: {e}\")\n",
    "\n",
    "def encodeFolder(folder_in, folder_out, transform, num_threads=8):\n",
    "    os.makedirs(folder_out, exist_ok=True)\n",
    "    song_paths = os.listdir(folder_in)\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_song, song_path, folder_in, folder_out, transform)\n",
    "            for song_path in song_paths\n",
    "        ]\n",
    "        for _ in tqdm(as_completed(futures), total=len(futures), desc=f\"Processing {folder_in}\"):\n",
    "            pass\n",
    "\n",
    "# Run for folders 50 to 98\n",
    "for index in range(0, 99):\n",
    "    folder_name = f\"E:/mtg-jamendo/{index:02}\"\n",
    "    encodeFolder(folder_name, \"E:/SongsDataset/MELSPEC/\", toMEL)"
   ],
   "id": "7efabc7a6ff6ecde",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
    "recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
    "f1_macro = f1_score(all_labels, all_preds, average='macro')"
   ],
   "id": "6cf296ffedc35404",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"Precision: {precision_macro}\\nRecall: {precision_macro}\\nF1: {precision_macro}\\n\")",
   "id": "7b2136c6260a727c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
