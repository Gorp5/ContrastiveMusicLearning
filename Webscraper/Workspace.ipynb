{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data & Training",
   "id": "ebf89474ab777d38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:34:36.693903Z",
     "start_time": "2025-04-16T17:34:32.717597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from Training import evaluate, train\n",
    "from Data import AudioDataset, retrieve_data"
   ],
   "id": "6afff8a0a232dd33",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-04-15T01:01:51.737134Z",
     "start_time": "2025-04-15T00:50:45.860867Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [11:05<00:00, 55.49s/it]\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": [
    "directory = \"\"#\"latents\\\\\" #\"reconstruction_test_latents\\\\\" #mtg-jamendo\n",
    "num_per = 1000\n",
    "count = 1\n",
    "for start in tqdm(range(5000, 16150, num_per)):\n",
    "    mtg_dataset = retrieve_data(\"E:\\SongsDataset\\\\mtg-jamendo\\\\\", directory, start=start, count=num_per, sample_length=256)\n",
    "    torch.save(mtg_dataset, f\"E:\\\\SongsDataset\\\\dataset{count}.pt\")\n",
    "\n",
    "    count += 1"
   ],
   "id": "b8e1130f3fe4d3cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:09:22.692766Z",
     "start_time": "2025-04-15T01:06:34.048814Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:48<00:00, 42.16s/it]\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "directory = \"\"#\"latents\\\\\" #\"reconstruction_test_latents\\\\\" #mtg-jamendo\n",
    "num_per = 1000\n",
    "count = 18\n",
    "for start in tqdm(range(0, 3973, num_per)):\n",
    "    spotify_dataset = retrieve_data(\"E:\\SongsDataset\\\\latents\\\\\", directory, start=start, count=num_per, sample_length=256)\n",
    "    torch.save(spotify_dataset, f\"E:\\\\SongsDataset\\\\dataset{count}.pt\")\n",
    "\n",
    "    count += 1"
   ],
   "id": "7b90b9c27234c4e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:11:20.975408Z",
     "start_time": "2025-04-15T01:09:38.806851Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:36<00:00,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([151741, 256, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "full_dataset = torch.load(f\"E:\\\\SongsDataset\\\\dataset1.pt\")\n",
    "for start in tqdm(range(2, 21)):\n",
    "    new_data = torch.load(f\"E:\\\\SongsDataset\\\\dataset{start}.pt\")\n",
    "    full_dataset = torch.cat((full_dataset, new_data))\n",
    "\n",
    "print(full_dataset.shape)"
   ],
   "id": "8f6b6090b53d58d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T01:14:01.919386Z",
     "start_time": "2025-04-15T01:12:54.761403Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 10,
   "source": "torch.save(full_dataset, \"E:\\\\SongsDataset\\\\full_dataset.pt\")",
   "id": "8c575f2f292ad01"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:34:37.082420Z",
     "start_time": "2025-04-16T17:34:36.735420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#full_dataset = torch.load(\"E:\\\\SongsDataset\\\\full_dataset.pt\")\n",
    "full_dataset = torch.load(\"E:\\\\SongsDataset\\\\dataset1.pt\")"
   ],
   "id": "932e5667035a22a1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:34:37.475960Z",
     "start_time": "2025-04-16T17:34:37.461961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==== Model & Optimizer ====\n",
    "num_heads = 8\n",
    "num_layers = 8\n",
    "d_model = 512\n",
    "latent_space = 64\n",
    "dim_feedforward = 512\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "device = \"cuda\""
   ],
   "id": "1112734e300ad7bf",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:34:37.552962Z",
     "start_time": "2025-04-16T17:34:37.533961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "num_samples, seq_length, embed_dim = full_dataset.shape\n",
    "\n",
    "train_len = int(len(full_dataset) * 0.9)\n",
    "train_set, test_set = random_split(full_dataset, [train_len, len(full_dataset) - train_len])\n",
    "\n",
    "train_dataset = AudioDataset(train_set)\n",
    "test_dataset = AudioDataset(test_set)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "d91d65a8dceff284",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:34:39.120020Z",
     "start_time": "2025-04-16T17:34:37.571962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Analyzer.Webscraper.AudioTransformerCNNReconstruction import AudioTransformerCNNReconstruction\n",
    "\n",
    "model = AudioTransformerCNNReconstruction(d_model=d_model, num_heads=num_heads, transformer_layers=num_layers, dim_feedforward=dim_feedforward, latent_space=latent_space, length=256, dropout=0.1001)"
   ],
   "id": "efe07f20b282113e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:34:42.181053Z",
     "start_time": "2025-04-16T17:34:39.140021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-5)"
   ],
   "id": "1cf6ca44ae7198c9",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:52:25.513613Z",
     "start_time": "2025-04-16T17:34:42.198054Z"
    }
   },
   "cell_type": "code",
   "source": "train(model, train_dataloader, test_dataloader, optimizer, num_epochs=4, device=device)",
   "id": "2dadf0068700f594",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:33<00:00,  4.16it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 0.9629 \t Validation Loss: 0.9629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:41<00:00,  3.83it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 12.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Training Loss: 0.8633 \t Validation Loss: 0.8633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:32<00:00,  4.20it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 12.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Training Loss: 0.8069 \t Validation Loss: 0.8069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:33<00:00,  4.16it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Training Loss: 0.7777 \t Validation Loss: 0.7777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:33<00:00,  4.16it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Training Loss: 0.7629 \t Validation Loss: 0.7629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:33<00:00,  4.15it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 13.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Training Loss: 0.7495 \t Validation Loss: 0.7495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:31<00:00,  4.25it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Training Loss: 0.7386 \t Validation Loss: 0.7386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:34<00:00,  4.14it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Training Loss: 0.7296 \t Validation Loss: 0.7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:34<00:00,  4.12it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Training Loss: 0.7239 \t Validation Loss: 0.7239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:49<00:00,  3.56it/s]\n",
      "100%|██████████| 44/44 [00:03<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Training Loss: 0.7184 \t Validation Loss: 0.7184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 104/390 [00:26<01:13,  3.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_dataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Coding\\SongAnalyzer\\Analyzer\\Webscraper\\Training.py:91\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, dataloader, test_dataloader, optimizer, num_epochs, device)\u001B[0m\n\u001B[0;32m     88\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;66;03m# print(prof.key_averages().table(sort_by=\"self_cuda_time_total\"))\u001B[39;00m\n\u001B[1;32m---> 91\u001B[0m     ls \u001B[38;5;241m=\u001B[39m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m     total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m ls\n\u001B[0;32m     94\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:26:43.431290Z",
     "start_time": "2025-04-16T17:26:42.728148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "reconstruction_examples = retrieve_data(\"E:\\SongsDataset\\\\\",  \"reconstruction_test_latents\\\\\", sample_length=256)\n",
    "\n",
    "# ==== Data Preparation ====\n",
    "song_set, _ = random_split(reconstruction_examples, [len(reconstruction_examples), 0])\n",
    "song_dataset = AudioDataset(song_set)\n",
    "song_dataloader = DataLoader(song_dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "fbc2621ca2ea37d3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Output Stuff",
   "id": "be18100accf986cc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:26:01.620573Z",
     "start_time": "2025-04-16T17:26:01.296574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = torch.load(\"AudioTransformerCNNReconstruction-LatentSpace64-Heads8-TrasformerLayers6-DModel256-Dropout0.1\\\\-Epoch-6.pt\", weights_only=False)\n",
    "evaluate(model, song_dataloader)"
   ],
   "id": "40f2daf24ce8dfd5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAudioTransformerCNNReconstruction-LatentSpace64-Heads8-TrasformerLayers6-DModel256-Dropout0.1\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m-Epoch-6.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m, weights_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m      2\u001B[0m evaluate(model, song_dataloader)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T17:27:31.118909Z",
     "start_time": "2025-04-16T17:27:29.323909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Output Stuff\n",
    "model = torch.load(\n",
    "    \"AudioTransformerCNNReconstruction-LatentSpace64-Heads8-TrasformerLayers8-DModel256-Dropout0.1\\\\-Epoch-13.pt\",\n",
    "    weights_only=False)\n",
    "evaluate(model, song_dataloader)"
   ],
   "id": "9d2e850eb318db1c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 23.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Reconstructive Loss: 0.5488527417\n",
      "Avg Contrastive Loss: 0.1242191568\n",
      "Avg Total Loss: 0.6731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6730718844466739"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "455f9eaa3c09be8b",
   "metadata": {},
   "source": [
    "from Loss import combined_loss\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "model.to(device)\n",
    "total_loss = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "new_song = []\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(song_dataloader):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        reconstructed = model(batch)\n",
    "\n",
    "        new_song.extend(reconstructed.to(\"cpu\"))\n",
    "\n",
    "        loss = combined_loss(reconstructed, batch)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from Loss import combined_loss\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model.eval()  # Set model to evaluation mode\n",
    "model.to(device)\n",
    "total_loss = 0.0\n",
    "num_batches = 0\n",
    "\n",
    "latent_space = []\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(song_dataloader):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        latent = model.to_latent(batch)\n",
    "\n",
    "        latent_space.extend(latent.to(\"cpu\"))\n",
    "\n",
    "        num_batches += 1"
   ],
   "id": "500f58f1e962f7d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(len(latent_space))\n",
    "print(len(latent_space[0]))\n",
    "print(len(latent_space[0][0]))"
   ],
   "id": "b136dab70b1d939c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6dc59bf50629e940",
   "metadata": {},
   "source": [
    "l = np.array(np.stack(new_song))\n",
    "np.save(\"reconstructed_song-256-Smaller-96.npy\", l.transpose())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "99e97d55b0fe4e2b",
   "metadata": {},
   "source": [
    "import IPython\n",
    "import numpy as np\n",
    "from music2latent import EncoderDecoder\n",
    "\n",
    "encdec = EncoderDecoder()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "44ccbf65f2c3ecb2",
   "metadata": {},
   "source": [
    "compressed_song = np.load(\"reconstructed_song-256-Bigger.npy\")\n",
    "wv_rec = encdec.decode(compressed_song)\n",
    "IPython.display.display(IPython.display.Audio(wv_rec, rate=44100))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "compressed_song = np.load(\"reconstructed_song-256-Smaller-13.npy\")\n",
    "wv_rec = encdec.decode(compressed_song)\n",
    "IPython.display.display(IPython.display.Audio(wv_rec, rate=44100))"
   ],
   "id": "82128da47c0d85b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "compressed_song = np.load(\"reconstructed_song-256-Smaller-96.npy\")\n",
    "wv_rec = encdec.decode(compressed_song)\n",
    "IPython.display.display(IPython.display.Audio(wv_rec, rate=44100))"
   ],
   "id": "37adcbe9ec1ff8a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:08:04.166519Z",
     "start_time": "2025-04-15T18:08:04.123520Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "769b32eba0fc225e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nvcc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mnvcc\u001B[49m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m-\u001B[39mversion\n",
      "\u001B[1;31mNameError\u001B[0m: name 'nvcc' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d8b8c30702ec38c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
